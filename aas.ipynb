{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####Cine 21 평론 게시판을 예시로 작성####\n",
    "\n",
    "def crawl(): #crawl 함수 정의\n",
    "    #필요모듈\n",
    "    import selenium \n",
    "    from selenium import webdriver\n",
    "    from bs4 import BeautifulSoup\n",
    "    \n",
    "    x=0\n",
    "    while x < 1000: #조건문 시작. 필요에 따라 수정 \n",
    "        x = (x+1)\n",
    "        y = (10*x +1) #x 값 정의\n",
    "        z = str(y) #x 값 스트링으로 변환. 밑의 주소에 입력시 int 는 입력이 안되어 str로 변환\n",
    "    \n",
    "        #텍스트 리스트 만들기\n",
    "        texts = []\n",
    "        \n",
    "        html = 'https://search.naver.com/search.naver?where=kin&kin_display=10&qt=&title=0&&answer=0&grade=0&choice=0&sec=0&nso=so%3Ar%2Ca%3Aall%2Cp%3Aall&query=간이과세&c_id=&c_name=&sm=tab_pge&kin_start=' #소스 페이지    \n",
    "        driver = webdriver.Chrome('/Users/stan/chromedriver') #드라이버 실행. 크롬 사용. 다른 드라이버 사용 가능\n",
    "            \n",
    "        driver.get(html + z) #html 과 z 를 조합한 주소로 크롬 실행\n",
    "            \n",
    "            #상위 엘리먼트 객체 불러오기\n",
    "        results = driver.find_elements_by_css_selector('dt.question') #li 태그가 붙은 부위 results 로 묶음\n",
    "        \n",
    "        links = [] #새창에 띄울 링크 리스트 생성\n",
    "            \n",
    "            #li 객체에서 a 태그가 붙은 객체 중, href 를 포함하는 객체를 포함하기\n",
    "        for i in range(0,9): #li 태그 객체중 19번 부터 31번 까지만 필요로 하기 떄문에 range 설정\n",
    "            link = results[i].find_element_by_tag_name(\"a\") #results, 즉 li 태그가 붙은 19~31 번 객체로 부터, a 태그가 붙은 위치 link 로 정의\n",
    "            links.append(link.get_attribute(\"href\")) # a 태그 가 붙은 링크가 포함하고 있음 href 항목을 links 리스트에 저장\n",
    "            \n",
    "            #새탭에 전부 출력\n",
    "        for link in links: #links 리스트의 모든 link 를\n",
    "            driver.execute_script('window.open(\"'+link+'\")') #새로운 창에서 실행            \n",
    "        \n",
    "        driver.switch_to.window(driver.window_handles[0]) # 창 변경\n",
    "            #크롤링\n",
    "        html = driver.page_source #창페이지 소스 긁어오기\n",
    "        soup = BeautifulSoup(html, 'html.parser') #소스 파싱\n",
    "        body = soup.select('div.question-content') #범위 셀렉트\n",
    "        texts.append(body) #리스트에 추출 텍스트 저장\n",
    "            \n",
    "            ###\n",
    "        driver.switch_to.window(driver.window_handles[1]) # 창 변경\n",
    "            #크롤링\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        body = soup.select('div.question-content')\n",
    "        texts.append(body)\n",
    "        \n",
    "            ###\n",
    "        driver.switch_to.window(driver.window_handles[2]) # 창 변경\n",
    "            #크롤링\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        body = soup.select('div.question-content')\n",
    "        texts.append(body)\n",
    "            \n",
    "            ###\n",
    "        driver.switch_to.window(driver.window_handles[3]) # 창 변경\n",
    "            #크롤링\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        body = soup.select('div.question-content')\n",
    "        texts.append(body)\n",
    "            \n",
    "            ###\n",
    "        driver.switch_to.window(driver.window_handles[4]) # 창 변경\n",
    "            #크롤링\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        body = soup.select('div.question-content')\n",
    "        texts.append(body)\n",
    "            \n",
    "            ###\n",
    "        driver.switch_to.window(driver.window_handles[5]) # 창 변경\n",
    "            #크롤링\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        body = soup.select('div.question-content')\n",
    "        texts.append(body)\n",
    "            \n",
    "            ###\n",
    "        driver.switch_to.window(driver.window_handles[6]) # 창 변경\n",
    "            #크롤링\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        body = soup.select('div.question-content')\n",
    "        texts.append(body)\n",
    "            \n",
    "            ###\n",
    "        driver.switch_to.window(driver.window_handles[7]) # 창 변경\n",
    "            #크롤링\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        body = soup.select('div.question-content')\n",
    "        texts.append(body)\n",
    "            \n",
    "            ###\n",
    "        driver.switch_to.window(driver.window_handles[8]) # 창 변경\n",
    "            #크롤링\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        body = soup.select('div.question-content')\n",
    "        texts.append(body)\n",
    "            \n",
    "            ###\n",
    "        driver.switch_to.window(driver.window_handles[9]) # 창 변경\n",
    "            #크롤링\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        body = soup.select('div.question-content')\n",
    "        texts.append(body)\n",
    "            \n",
    "\n",
    "        driver.quit() #드라이버 종료\n",
    "        \n",
    "        if z is '0': #첫페이지 실행시\n",
    "            f = open(\"jjh12.txt\",\"w+\") #파일생성 및 쓰기\n",
    "            print(texts, file=f) #texts 에 저장된 리스트 파일에 쓰기\n",
    "        else: #첫페이지 후에 오픈되는 페이지\n",
    "            f = open(\"jjh12.txt\", \"a+\") #기존 파일 열고 추가 하기\n",
    "            print(texts, file=f) #text 에 저장된 리스트 파일에 추가\n",
    "                \n",
    "\n",
    "        #while 문 조건 제한 부분. 필요에 따라 수정 가능\n",
    "        if y < 71: \n",
    "            continue\n",
    "        if y > 81:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
